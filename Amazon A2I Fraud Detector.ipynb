{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Augmented AI (Amazon A2I) integration with Amazon Fraud Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visit https://github.com/aws-samples/amazon-a2i-sample-jupyter-notebooks for all A2I Sample Notebooks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introduction](#Introduction)\n",
    "2. [Prerequisites](#Setup)\n",
    "    1. [Workteam](#Workteam)\n",
    "    2. [Notebook Permission](#Notebook-Permission)\n",
    "3. [Client Setup](#Client-Setup)\n",
    "4. [Create Control Plane Resources](#Create-Control-Plane-Resources)\n",
    "    1. [Create Human Task UI](#Create-Human-Task-UI)\n",
    "    2. [Create Flow Definition](#Create-Flow-Definition)\n",
    "5. Scenario: When Activation Conditions are met, and a Human Loop is created\n",
    "    1. [Check Status of Human Loop](#Check-Status-of-Human-Loop)\n",
    "    2. [Wait For Workers to Complete Task](#Wait-For-Workers-to-Complete-Task)\n",
    "    3. [Check Status of Human Loop](#Check-Status-of-Human-Loop)\n",
    "    4. [View Task Results](#View-Task-Results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Amazon Augmented AI (Amazon A2I) makes it easy to build the workflows required for human review of ML predictions. Amazon A2I brings human review to all developers, removing the undifferentiated heavy lifting associated with building human review systems or managing large numbers of human reviewers. \n",
    "\n",
    "Amazon A2I provides built-in human review workflows for common machine learning use cases, such as content moderation and text extraction from documents, which allows predictions from Amazon Rekognition and Amazon Textract to be reviewed easily. You can also create your own workflows for ML models built on Amazon SageMaker or any other tools. Using Amazon A2I, you can allow human reviewers to step in when a model is unable to make a high confidence prediction or to audit its predictions on an on-going basis. Learn more here: https://aws.amazon.com/augmented-ai/\n",
    "\n",
    "In this tutorial, we will show how you can use Amazon A2I directly within your API calls to Amazon Rekognition's Detect Moderation Labels API. \n",
    "\n",
    "For more in depth instructions, visit https://docs.aws.amazon.com/sagemaker/latest/dg/a2i-getting-started.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To incorporate Amazon A2I into your human review workflows, you need three resources:\n",
    "\n",
    "* A **worker task template** to create a worker UI. The worker UI displays your input data, such as documents or images, and instructions to workers. It also provides interactive tools that the worker uses to complete your tasks. For more information, see https://docs.aws.amazon.com/sagemaker/latest/dg/a2i-instructions-overview.html\n",
    "\n",
    "* A **human review workflow**, also referred to as a flow definition. You use the flow definition to configure your human workforce and provide information about how to accomplish the human review task. For built-in task types, you also use the flow definition to identify the conditions under which a review human loop is triggered. For example, with Amazon Rekognition can perform image content moderation using machine learning. You can use the flow definition to specify that an image will be sent to a human for content moderation review if Amazon Rekognition's confidence score output is low for your use case. You can create a flow definition in the Amazon Augmented AI console or with the Amazon A2I APIs. To learn more about both of these options, see https://docs.aws.amazon.com/sagemaker/latest/dg/a2i-create-flow-definition.html\n",
    "\n",
    "* A **human loop** to start your human review workflow. When you use one of the built-in task types, the corresponding AWS service creates and starts a human loop on your behalf when the conditions specified in your flow definition are met or for each object if no conditions were specified. When a human loop is triggered, human review tasks are sent to the workers as specified in the flow definition.\n",
    "\n",
    "When using a custom task type, you start a human loop using the Amazon Augmented AI Runtime API. When you call StartHumanLoop in your custom application, a task is sent to human reviewers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Latest SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's get the latest installations of our dependencies\n",
    "!pip install --upgrade pip\n",
    "!pip install botocore --upgrade\n",
    "!pip install boto3 --upgrade\n",
    "!pip install -U botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We need to set up the following data:\n",
    "* `region` - Region to call A2I\n",
    "* `bucket` - A S3 bucket accessible by the given role\n",
    "    * Used to store the sample images & output results\n",
    "    * Must be within the same region A2I is called from\n",
    "* `role` - The IAM role used as part of StartHumanLoop. By default, this notebook will use the execution role\n",
    "* `workteam` - Group of people to send the work to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "\n",
    "REGION = boto3.session.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and Setup S3 Bucket and Paths\n",
    "Create your own S3 bucket and replace the following with that bucket name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the following with your bucket name\n",
    "BUCKET = 'a2i-demos-2020'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your bucket, `BUCKET` must be located in the same AWS Region that you are using to run this notebook. This cell checks if they are located in the same Region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazon S3 (S3) client\n",
    "s3 = boto3.client('s3', REGION)\n",
    "bucket_region = s3.head_bucket(Bucket=BUCKET)['ResponseMetadata']['HTTPHeaders']['x-amz-bucket-region']\n",
    "assert bucket_region == REGION, \"Your S3 bucket {} and this notebook need to be in the same region.\".format(BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Permission\n",
    "\n",
    "The AWS IAM Role used to execute the notebook needs to have the following permissions:\n",
    "\n",
    "* FraudDetectorFullAccess\n",
    "* SagemakerFullAccess\n",
    "* AmazonSageMakerMechanicalTurkAccess (if using MechanicalTurk as your Workforce)\n",
    "* S3 Read and Write Access to the bucket you specified in `BUCKET`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Setting Role to the default SageMaker Execution Role\n",
    "ROLE = get_execution_role()\n",
    "display(ROLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visit: https://docs.aws.amazon.com/sagemaker/latest/dg/a2i-permissions-security.html to add the necessary permissions to your role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workteam or Workforce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A workforce is the group of workers that you have selected to label your dataset. You can choose either the Amazon Mechanical Turk workforce, a vendor-managed workforce, or you can create your own private workforce for human reviews. Whichever workforce type you choose, Amazon Augmented AI takes care of sending tasks to workers. \n",
    "\n",
    "When you use a private workforce, you also create work teams, a group of workers from your workforce that are assigned to Amazon Augmented AI human review tasks. You can have multiple work teams and can assign one or more work teams to each job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create your Workteam, visit the instructions here: https://docs.aws.amazon.com/sagemaker/latest/dg/sms-workforce-management.html\n",
    "\n",
    "NOTE: After you have created your workteam, replace WORKTEAM_ARN below with your own Workteam ARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKTEAM_ARN = \"arn:aws:sagemaker:us-east-1:1234567890:workteam/private-crowd/a2i-demo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are going to setup the clients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import clear_output\n",
    "display(HTML(\"<style>.container { width:90% }</style>\"))\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import uuid \n",
    "from datetime import datetime\n",
    "import io\n",
    "\n",
    "# -- AWS stuff -- \n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# -- sklearn --\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, roc_auc_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "# Pretty print setup\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "# Function to pretty-print AWS SDK responses\n",
    "def print_response(response):\n",
    "    if 'ResponseMetadata' in response:\n",
    "        del response['ResponseMetadata']\n",
    "    pp.pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazon SageMaker client\n",
    "sagemaker = boto3.client('sagemaker', REGION)\n",
    "\n",
    "\n",
    "# Amazon Augmented AI (A2I) Runtime client\n",
    "a2i_runtime_client = boto3.client('sagemaker-a2i-runtime', REGION)\n",
    "\n",
    "\n",
    "# -- initialize the AFD client \n",
    "client = boto3.client('frauddetector')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Fraud Detector Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate fraud predictions, Amazon Fraud Detector uses machine learning models that are trained\n",
    "with your historical fraud data. Each model is trained using a model type, which is a specialized recipe to\n",
    "build a fraud detection model for a specific fraud use case. Deployed models are imported to detectors,\n",
    "where you can configure decision logic (for example, rules) to interpret the modelâ€™s score and assign\n",
    "outcomes such as pass or send transaction to a human investigator for review.\n",
    "\n",
    "You can use the AWS Console to create and manage models and detector versions. Alternatively, you can\n",
    "use the AWS Command Line Interface (AWS CLI) or one of the Amazon Fraud Detector SDKs.\n",
    "Amazon Fraud Detector components include events, entities, labels, models, rules, variables, outcomes,\n",
    "and detectors. Using these components, you can build an evaluation that contains your fraud detection\n",
    "logic.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Create a fraud detector model using the console, please refer to the link below\n",
    " https://docs.aws.amazon.com/frauddetector/latest/ug/frauddetector.pdf\n",
    " \n",
    " ### To Create a fraud detector model using an SDK / Python notebook, please refer to the link below\n",
    "https://github.com/aws-samples/aws-fraud-detector-samples\n",
    "#### NOTE:\n",
    "The following model is create using the default data set provided by Amazon Fraud Detector (at https://docs.aws.amazon.com/frauddetector/latest/ug/samples/training_data.zip)\n",
    "\n",
    "After you create your own Fraud Detector Model, replace the MODEL_NAME, DETECTOR_NAME, EVENT_TYPE and ENTITY_TYPE with your  fraud detector model values\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'sample_fraud_detection'\n",
    "DETECTOR_NAME = 'fraud_detector'\n",
    "EVENT_TYPE = 'registration'\n",
    "ENTITY_TYPE = 'customer'\n",
    "\n",
    "# -- model performance summary -- \n",
    "auc = client.describe_model_versions(\n",
    "    modelId= MODEL_NAME,\n",
    "    modelVersionNumber='1.0',\n",
    "    modelType='ONLINE_FRAUD_INSIGHTS',\n",
    "    maxResults=10\n",
    ")['modelVersionDetails'][0]['trainingResult']['trainingMetrics']['auc']\n",
    "\n",
    "\n",
    "df_model = pd.DataFrame(client.describe_model_versions(\n",
    "    modelId= MODEL_NAME,\n",
    "    modelVersionNumber='1.0',\n",
    "    modelType='ONLINE_FRAUD_INSIGHTS',\n",
    "    maxResults=10\n",
    ")['modelVersionDetails'][0]['trainingResult']['trainingMetrics']['metricDataPoints'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(df_model[\"fpr\"], df_model[\"tpr\"], color='darkorange',\n",
    "         lw=2, label='ROC curve (area = %0.3f)' % auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title( MODEL_NAME + ' ROC Chart')\n",
    "plt.legend(loc=\"lower right\",fontsize=12)\n",
    "plt.axvline(x = 0.02 ,linewidth=2, color='r')\n",
    "plt.axhline(y = 0.73 ,linewidth=2, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the fraud detector with a sample data record\n",
    "Using the fraud detector client, invoke the model endpoint with a sample record and examine the results including fraud detection score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eventId = uuid.uuid1()\n",
    "timestampStr = '2013-07-16T19:00:00Z'\n",
    "\n",
    "# Construct a sample data record\n",
    "\n",
    "rec = {\n",
    "   'ip_address': '36.72.99.64',\n",
    "   'email_address': 'fake_bakermichael@example.net',\n",
    "   'billing_state' : 'NJ',\n",
    "   'user_agent' : 'Mozilla',\n",
    "   'billing_postal' : '32067',\n",
    "   'phone_number' :'703-989-7890',\n",
    "   'user_agent' : 'Mozilla',\n",
    "   'billing_address' :'12351 Amanda Knolls Fake St'\n",
    "}\n",
    "\n",
    "\n",
    "pred = client.get_event_prediction(detectorId=DETECTOR_NAME, \n",
    "                                       detectorVersionId='1',\n",
    "                                       eventId = str(eventId),\n",
    "                                       eventTypeName = EVENT_TYPE,\n",
    "                                       eventTimestamp = timestampStr, \n",
    "                                       entities = [{'entityType': ENTITY_TYPE, 'entityId':str(eventId.int)}],\n",
    "                                       eventVariables=rec) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract/print the model score\n",
    "pred['modelScores'][0]['scores']['sample_fraud_detection_insightscore']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Control Plane Resources\n",
    "\n",
    "Here we'll be constructing the following control plane resources: Human Task UI and Flow Definition, using the SageMaker CreateTaskUI and CreateFlowDefinition APIs, respectively.\n",
    "\n",
    "These resources can be created once and used to drive any subsequent A2I human loops.\n",
    "\n",
    "NOTE: The following template models a \"Claim\" - i.e. mark if a given claim is fraudulent, valid claim or needs further investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"<script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\n",
    "\n",
    "<crowd-form>\n",
    "      <crowd-classifier\n",
    "          name=\"category\"\n",
    "          categories=\"['Fradulent Claim', 'Valid Claim', 'Needs furthur Investigation']\"\n",
    "          header=\"Select the most relevant category\"\n",
    "      >\n",
    "      <classification-target>\n",
    "        <h3><strong>Risk Score (out of 1000): </strong><span style=\"color: #ff9900;\">{{ task.input.score.sample_fraud_detection_insightscore }}</span></h3>\n",
    "        <hr>\n",
    "\t<h3> Claim Details </h3>\n",
    "        <p style=\"padding-left: 50px;\"><strong>Email Address   :  </strong>{{ task.input.taskObject.email_address }}</p>\n",
    "        <p style=\"padding-left: 50px;\"><strong>Billing Address :  </strong>{{ task.input.taskObject.billing_address }}</p>\n",
    "        <p style=\"padding-left: 50px;\"><strong>Billing State   :  </strong>{{ task.input.taskObject.billing_state }}</p>\n",
    "        <p style=\"padding-left: 50px;\"><strong>Billing Zip     :  </strong>{{ task.input.taskObject.billing_postal }}</p>\n",
    "        <p style=\"padding-left: 50px;\"><strong>Originating IP  :  </strong>{{ task.input.taskObject.ip_address }}</p>\n",
    "        <p style=\"padding-left: 50px;\"><strong>Phone Number    :  </strong>{{ task.input.taskObject.phone_number }}</p>\n",
    "        <p style=\"padding-left: 50px;\"><strong>User Agent      :  </strong>{{ task.input.taskObject.user_agent }}</p>\n",
    "        \n",
    "      </classification-target>\n",
    "      \n",
    "      <full-instructions header=\"Claim Verification instructions\">\n",
    "         <ol>\n",
    "        <li><strong>Review</strong> the claim application and documents carefully.</li>\n",
    "        <li>Mark the claim as valid or fraudulent</li>\n",
    "      </ol>\n",
    "      </full-instructions>\n",
    "\n",
    "      <short-instructions>\n",
    "       Choose the most relevant category that is expressed by the text. \n",
    "      </short-instructions>\n",
    "    </crowd-classifier>\n",
    "\n",
    "</crowd-form>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_task_ui(task_ui_name, template):\n",
    "    '''\n",
    "    Creates a Human Task UI resource.\n",
    "\n",
    "    Returns:\n",
    "    struct: HumanTaskUiArn\n",
    "    '''\n",
    "    response = sagemaker.create_human_task_ui(\n",
    "        HumanTaskUiName=task_ui_name,\n",
    "        UiTemplate={'Content': template})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Augmented AI task UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task UI name - this value is unique per account and region. You can also provide your own value here.\n",
    "taskUIName = 'fraud'+ str(uuid.uuid1())\n",
    "\n",
    "# Create task UI\n",
    "humanTaskUiResponse = create_task_ui(taskUIName, template)\n",
    "humanTaskUiArn = humanTaskUiResponse['HumanTaskUiArn']\n",
    "print(humanTaskUiArn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = f's3://{BUCKET}/a2i-results'\n",
    "\n",
    "def create_flow_definition(flow_definition_name):\n",
    "    '''\n",
    "    Creates a Flow Definition resource\n",
    "\n",
    "    Returns:\n",
    "    struct: FlowDefinitionArn\n",
    "    '''\n",
    "    response = sagemaker.create_flow_definition(\n",
    "            FlowDefinitionName= flow_definition_name,\n",
    "            RoleArn= ROLE,\n",
    "            HumanLoopConfig= {\n",
    "                \"WorkteamArn\": WORKTEAM_ARN,\n",
    "                \"HumanTaskUiArn\": humanTaskUiArn,\n",
    "                \"TaskCount\": 1,\n",
    "                \"TaskDescription\": \"Please review the claim data and flag for potential fraud\",\n",
    "                \"TaskTitle\": \"Review and Approve / Reject claim.\"\n",
    "            },\n",
    "            OutputConfig={\n",
    "                \"S3OutputPath\" : OUTPUT_PATH\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    return response['FlowDefinitionArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow definition name - this value is unique per account and region. You can also provide your own value here.\n",
    "#uniqueId = str(uuid.uuid4())\n",
    "uniqueId = str(int(round(time.time() * 1000)))\n",
    "flowDefinitionName = f'fraud-detector-a2i-{uniqueId}'\n",
    "#flowDefinitionName = 'fraud-detector-a2i' \n",
    "\n",
    "flowDefinitionArn = create_flow_definition(flowDefinitionName)\n",
    "print(flowDefinitionArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Moderation Labels with AWS Rekognition\n",
    "\n",
    "Let's call Amazon Rekognition to detect moderation labels on the sample images stored in S3 based on the steps above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start human loop if the model risk score exceeds a certain treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'a2i-demos-2020'\n",
    "OUTPUT_PATH = f's3://{BUCKET}/a2i-results'\n",
    "\n",
    "FraudScore= pred['modelScores'][0]['scores']['sample_fraud_detection_insightscore']\n",
    "print(FraudScore)\n",
    "\n",
    "## SET YOUR OWN THRESHOLD HERE\n",
    "SCORE_THRESHOLD  = 900\n",
    "\n",
    "if FraudScore > SCORE_THRESHOLD  :\n",
    "    # Create the human loop input JSON object\n",
    "    humanLoopInput = {\n",
    "        'score' : pred['modelScores'][0]['scores'],\n",
    "        'taskObject': rec\n",
    "    }\n",
    "\n",
    "    print(json.dumps(humanLoopInput))\n",
    "    humanLoopName = 'Fraud-detector-' + str(int(round(time.time() * 1000)))\n",
    "    print('Starting human loop - ' + humanLoopName)\n",
    "\n",
    "    response = a2i_runtime_client.start_human_loop(\n",
    "                            HumanLoopName=humanLoopName,\n",
    "                            FlowDefinitionArn= flowDefinitionArn,\n",
    "                            HumanLoopInput={\n",
    "                                'InputContent': json.dumps(humanLoopInput)\n",
    "                                }\n",
    "                            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Status of Human Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_human_loops_in_workflow = a2i_runtime_client.list_human_loops(FlowDefinitionArn=flowDefinitionArn)['HumanLoopSummaries']\n",
    "\n",
    "for human_loop in all_human_loops_in_workflow:\n",
    "    print(f'\\nHuman Loop Name: {human_loop[\"HumanLoopName\"]}')\n",
    "    print(f'Human Loop Status: {human_loop[\"HumanLoopStatus\"]} \\n')\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait For Workers to Complete Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workteamName = WORKTEAM_ARN[WORKTEAM_ARN.rfind('/') + 1:]\n",
    "print(\"Navigate to the private worker portal and do the tasks. Make sure you've invited yourself to your workteam!\")\n",
    "print('https://' + sagemaker.describe_workteam(WorkteamName=workteamName)['Workteam']['SubDomain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Status of Human Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_human_loops_in_workflow = a2i_runtime_client.list_human_loops(FlowDefinitionArn=flowDefinitionArn)['HumanLoopSummaries']\n",
    "\n",
    "completed_loops = []\n",
    "for human_loop in all_human_loops_in_workflow:\n",
    "    print(f'\\nHuman Loop Name: {human_loop[\"HumanLoopName\"]}')\n",
    "    print(f'Human Loop Status: {human_loop[\"HumanLoopStatus\"]} \\n')\n",
    "    print('\\n')\n",
    "    if human_loop['HumanLoopStatus'] == 'Completed':\n",
    "        completed_loops.append(human_loop['HumanLoopName'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completed_loops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Task Results  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once work is completed, Amazon A2I stores results in your S3 bucket and sends a Cloudwatch event. Your results should be available in the S3 OUTPUT_PATH when all work is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "def retrieve_a2i_results_from_output_s3_uri(bucket, a2i_s3_output_uri):\n",
    "    '''\n",
    "    Gets the json file published by A2I and returns a deserialized object\n",
    "    '''\n",
    "    splitted_string = re.split('s3://' +  bucket + '/', a2i_s3_output_uri)\n",
    "    output_bucket_key = splitted_string[1]\n",
    "\n",
    "    response = s3.get_object(Bucket=bucket, Key=output_bucket_key)\n",
    "    content = response[\"Body\"].read()\n",
    "    return json.loads(content)\n",
    "    \n",
    "\n",
    "for human_loop_name in completed_loops:\n",
    "\n",
    "    describe_human_loop_response = a2i_runtime_client.describe_human_loop(\n",
    "        HumanLoopName=human_loop_name\n",
    "    )\n",
    "    \n",
    "    print(f'\\nHuman Loop Name: {describe_human_loop_response[\"HumanLoopName\"]}')\n",
    "    print(f'Human Loop Status: {describe_human_loop_response[\"HumanLoopStatus\"]}')\n",
    "    print(f'Human Loop Output Location: : {describe_human_loop_response[\"HumanLoopOutput\"][\"OutputS3Uri\"]} \\n')\n",
    "    \n",
    "    # Uncomment below line to print out a2i human answers\n",
    "    pp.pprint(retrieve_a2i_results_from_output_s3_uri(BUCKET, describe_human_loop_response['HumanLoopOutput']['OutputS3Uri']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
